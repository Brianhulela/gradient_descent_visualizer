# Gradient Descent Visualizer

![Cover Image](https://github.com/Brianhulela/gradient_descent_visualizer/blob/master/surface_and_descent_path.png)

This repository provides an interactive **visualization of Gradient Descent** algorithm. It demonstrates how the algorithm iteratively adjusts the linear regression parameters (`b0` and `b1`) to minimize the **Mean Squared Error (MSE)**, ultimately converging towards the optimal solution. The visualizations offer a clear view of how the parameters evolve over time, with 3D surface plots of the loss function during the optimization process.

## Key Features:
- **Gradient Descent Algorithm**: See how gradient descent converges to the optimal values for the parameters (`b0` and `b1`) based on the loss function.
- **Interactive Visualizations**: Dynamic 3D surface plots that illustrate the loss function and its relationship with parameters, with color gradients for easy interpretation.

## Insights You Can Gain:
- Understand the relationship between the parameters (`b0` and `b1`) and the MSE, helping you visualize how gradient descent minimizes the loss function.
- Compare the stability and speed of **Gradient Descent** in approaching the optimal solution.
- Gain an intuitive understanding of optimization algorithms used in machine learning and statistics.

## Explore More:
To dive deeper into the concepts behind gradient descent and how this visualization works, you can check out the full explanation in the [Medium article here](https://link-to-medium-article.com). It covers the theory, mathematical details, and practical implementation behind the visualizations in this repository.

Feel free to explore the code, experiment with different datasets, and visualize your own gradient descent journeys!
